<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- Stop output INFO at start -->
    <statusListener class="ch.qos.logback.core.status.NopStatusListener" />

    <!--
    Можно использовать консоль для отладки
    Но только во время локальной разработки
    -->
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <!-- <pattern>[%date{ISO8601}] [%level] [%logger] %msg %n</pattern> -->
            <pattern>%msg</pattern>
        </encoder>
    </appender>

    <!--
    Если данных много можно сохранять в файл но опять же только во время разработки
    При запуске локальной отладки фал будет сохраняться на диск
    В режиме кластер файл будет сохраняться внутри каждого докер контейнера т.е. в оперативной памяти
    -->
    <appender name="FILE" class="ch.qos.logback.core.FileAppender">
        <file>./logs/application.log</file>
        <immediateFlush>false</immediateFlush>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>app_%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>7</maxHistory>
            <totalSizeCap>5MB</totalSizeCap>
        </rollingPolicy>
        <encoder>
            <pattern>[%date{ISO8601}] [%level] [%logger] - %msg {%mdc}%n</pattern>
        </encoder>
    </appender>

    <!--
    В продуктиве если нужны логи для мониторинга раоты системы их следует отправлять в Кафку
    -->
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder>
            <pattern>[%date{ISO8601}@%logger{36}] %msg</pattern>
        </encoder>
        <topic>project_bi_005_logs</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy" />
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy" />
        <appendTimestamp>true</appendTimestamp>
        <producerConfig>bootstrap.servers=broker1:9092,broker2:9092,broker3:9092</producerConfig>
    </appender>

    <appender name="ASYNC" class="ch.qos.logback.classic.AsyncAppender">
        <queueSize>8192</queueSize>
        <neverBlock>true</neverBlock>
        <appender-ref ref="kafkaAppender" />
    </appender>

    <!-- Для всех кто свистит устанавливаем уровень -->
    <logger name="akka" level="WARN" />
    <!--
    <logger name="akka.cluster.Cluster" level="ERROR" />
    <logger name="akka.actor.ActorSystemImpl" level="ERROR" />
    <logger name="akka.actor.LocalActorRef" level="ERROR" />
    <logger name="a.kafka.internal.SingleSourceLogic" level="OFF" />
    <logger name="akka.stream.Materializer" level="ERROR" />
    <logger name="a.r.artery.tcp.ArteryTcpTransport" level="ERROR" />
    -->
    <logger name="akka.event.slf4j.Slf4jLogger" level="WARN" />
    <logger name="com.lightbend.lagom" level="ERROR" />
    <logger name="org.apache.cassandra" level="WARN" />
    <logger name="com.datastax.driver" level="ERROR" />
    <logger name="com.datastax.driver.core.ControlConnection" level="OFF" />
    <logger name="org.apache.kafka" level="ERROR" />

    <!-- Это всё наше -->
    <logger name="app" level="DEBUG" />
    <logger name="cluster" level="DEBUG" />
    <logger name="Stream_Subscriber" level="DEBUG" />

    <root level="INFO">
        <appender-ref ref="STDOUT"/>
        <!--<appender-ref ref="ASYNC"/>-->
    </root>
</configuration>