# Конфигурация для запуска через docker-compose локально на любой машине

application {
  name = "Project BI / MSV-005"
  version = "0.0.1"
  cluster-name = "project-bi-msv005"
  run_type = "debug"
  node.roles = ${?NODE_ROLES}
}

clustering {
  ip = "127.0.0.1"
  ip = ${?CLUSTER_IP}

  port = 2553
  port = ${?CLUSTER_PORT}

  seed-ip = "127.0.0.1"
  seed-ip = ${?CLUSTER_SEED_IP}

  seed-port = 2553
  seed-port = ${?CLUSTER_SEED_PORT}
}

akka {
  loglevel = "INFO"
  log-config-on-start = on

  http.server.websocket.periodic-keep-alive-max-idle = 3 seconds

  actor {
    provider = cluster

    deployment {
      "/ws-sessions/*" {
        router = round-robin-group
        routees.paths = ["/user/ws-sessions/ws-session"]
        cluster {
          enabled = on
          allow-local-routees = on
        }
      }
    }

    serializers {
      jackson-json = "akka.serialization.jackson.JacksonJsonSerializer"
    }

    serialization-bindings {
      "kz.altyn.bi.msv005.JsonSerializable" = jackson-json
    }
  }

  remote {
    log-remote-lifecycle-events = on
    artery {
      enabled = on
      transport = tcp
      canonical.port = ${clustering.port}
      canonical.hostname = ${clustering.ip}
    }
  }

  cluster {
    seed-nodes = [
      "akka://"${application.cluster-name}"@"${clustering.seed-ip}":"${clustering.seed-port}
    ]
    auto-down-unreachable-after = 10s
    roles = []
    downing-provider-class = "akka.cluster.sbr.SplitBrainResolverProvider"
  }

  kafka {
    producer {
      # Config path of Akka Discovery method
      # "akka.discovery" to use the Akka Discovery method configured for the ActorSystem
      discovery-method = akka.discovery

      # Set a service name for use with Akka Discovery
      # https://doc.akka.io/docs/alpakka-kafka/current/discovery.html
      service-name = ""

      # Timeout for getting a reply from the discovery-method lookup
      resolve-timeout = 3 seconds

      # Tuning parameter of how many sends that can run in parallel.
      # In 2.0.0: changed the default from 100 to 10000
      parallelism = 100

      # Duration to wait for `KafkaProducer.close` to finish.
      close-timeout = 60s

      # Call `KafkaProducer.close` when the stream is shutdown. This is important to override to false
      # when the producer instance is shared across multiple producer stages.
      close-on-producer-stop = true

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the producer stages. Some blocking may occur.
      # When this value is empty, the dispatcher configured for the stream
      # will be used.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # The time interval to commit a transaction when using the `Transactional.sink` or `Transactional.flow`
      # for exactly-once-semantics processing.
      eos-commit-interval = 100ms

      # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
      # can be defined in this configuration section.
      kafka-clients {
        bootstrap.servers = "broker1:9092,broker2:9092,broker3:9092"
      }
    }

    consumer {
      # Tuning property of scheduled polls.
      poll-interval = 50ms

      # Tuning property of the `KafkaConsumer.poll` parameter.
      # Note that non-zero value means that blocking of the thread that
      # is executing the stage will be blocked.
      poll-timeout = 50ms

      # The stage will be await outstanding offset commit requests before
      # shutting down, but if that takes longer than this timeout it will
      # stop forcefully.
      stop-timeout = 30s

      # How long to wait for `KafkaConsumer.close`
      close-timeout = 20s

      # If offset commit requests are not completed within this timeout
      # the returned Future is completed `TimeoutException`.
      commit-timeout = 15s

      # If the KafkaConsumer can't connect to the broker the poll will be
      # aborted after this timeout. The KafkaConsumerActor will throw
      # org.apache.kafka.common.errors.WakeupException, which can be handled
      # with Actor supervision strategy.
      wakeup-timeout = 10s

      # Fully qualified config path which holds the dispatcher configuration
      # to be used by the KafkaConsumerActor. Some blocking may occur.
      use-dispatcher = "akka.kafka.default-dispatcher"

      # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
      # can be defined in this configuration section.
      kafka-clients {
        # auto-commit disabled by default
        # Setting enable.auto.commit means that offsets are committed automatically
        #  with a frequency controlled by the config auto.commit.interval.ms.
        enable.auto.commit = true

        auto.offset.reset = "latest"
        auto.commit.interval.ms = 10000

        bootstrap.servers = "broker1:9092,broker2:9092,broker3:9092"
      }
    }
  }
}

datastax-java-driver {
  # https://docs.datastax.com/en/developer/java-driver/4.9/manual/core/configuration/reference/
  basic {
    contact-points = [ "casdb1:9042","casdb2:9042","casdb3:9042" ]
    load-balancing-policy.local-datacenter = datacenter1
    session-name = ${application.cluster-name}
    request {
      timeout = 15 seconds
      consistency = ALL
      page-size = 5000
      serial-consistency = SERIAL
      default-idempotence = false
    }
  }

  advanced.protocol.version = V4
  advanced.reconnect-on-init = true
  advanced.reconnection-policy {
    class = ExponentialReconnectionPolicy
    base-delay = 1 second
    max-delay = 60 seconds
  }

  advanced.speculative-execution-policy {
    class = ConstantSpeculativeExecutionPolicy
    max-executions = 3
    delay = 100 milliseconds
  }
}

kafka {
  groupid = ${application.cluster-name}"-akka-group"
}

ksqldb {
    contact-points = "ksql1:8088,ksql1:8089,ksql1:8090"
    contact-points = ${?KSQLDB_CONTACT_POINTS}
}

schema-registry {
    url = "http://zookeep:8081"
    url = ${?SCHEMA_REGISTRY_URL}
}

http {
  ip = "0.0.0.0"
  ip = ${?SERVER_IP}

  port = 6677
  port = ${?SERVER_PORT}

  ws_port = 7766
  ws_port = ${?WS_SERVER_PORT}
}

oracledb {
  tns = "jdbc:oracle:thin:@(DESCRIPTION=(ADDRESS_LIST=(ADDRESS=(PROTOCOL=TCP)(HOST=dbdwh.hsbk.nb)(PORT=1521)))(CONNECT_DATA=(SERVICE_NAME=DWH)))"
  user = "AQ_USER"
  pass = "L0b6bHWvD"
}

oracledb {
  tns ="jdbc:oracle:thin:@//localhost:1521/XE"
  user = "db_user"
  pass = "db_password"
  jmsq = "APP.DATA_QUEUE"
}

slick-oracle {
  profile = "slick.jdbc.OracleProfile$"
  db {
    dataSourceClass = "slick.jdbc.DriverDataSource"
    properties = {
      driver = "oracle.jdbc.OracleDriver"
      url = ${oracledb.tns}
      user = ${oracledb.user}
      password = ${oracledb.pass}
    }
    numThreads = 1
  }
}

xmlservice {
  endpoint = "http://10.220.1.17:1520/soa_test/httpadapter"
  timeout = 10 seconds
}
